{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9123c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd                          # Data loading and manipulation\n",
    "import numpy as np                           # Numerical operations\n",
    "import matplotlib.pyplot as plt              # Plotting\n",
    "import seaborn as sns                        # Advanced plotting (barplots)\n",
    "import pickle                                # Model serialization\n",
    "\n",
    "from sklearn.model_selection import train_test_split     # Train/test splitting\n",
    "from sklearn.metrics import accuracy_score, f1_score     # Performance metrics\n",
    "from sktime.classification.kernel_based import TimeSeriesSVC  # SVM for time series\n",
    "from sktime.dists_kernels import AggrDist           # Aggregated distance kernel\n",
    "from sklearn.gaussian_process.kernels import RBF         # Radial basis function kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbf05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Data import and merging ---\n",
    "# Load Sentinel-2 index data\n",
    "loaded_data = pd.read_csv('path/to/your/data.csv', delimiter=',')\n",
    "\n",
    "loaded_data = loaded_data.assign(date=(loaded_data['system:index'].str[0:9]))\n",
    "\n",
    "# Load precomputed cluster assignments and merge\n",
    "data_cluster=pd.read_csv('path/to/your/data.csv', delimiter=',')\n",
    "\n",
    "\n",
    "# Sloučení na základě společného sloupce (např. \"ID\")\n",
    "merged_data = loaded_data.merge(data_cluster, on='ID', how='inner')\n",
    "\n",
    "# Convert date to datetime format\n",
    "merged_data['date'] = pd.to_datetime(loaded_data['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cloudy/snowy observations\n",
    "filtered_data = merged_data[(merged_data['NDSI'] < 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b75b0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Feature configuration ---\n",
    "# Univariate features to evaluate\n",
    "features = ['NDVI', 'EVI', 'NBR', 'NDMI','NDRE', 'MSAVI', 'FAPAR', 'LAI', 'TCW', 'WNDII']\n",
    "# Define multivariate feature combinations\n",
    "multivariate_combinations = {\n",
    "    'EVI_NDVI_MSAVI_NDMI_TCW': ['EVI', 'NDVI', 'MSAVI', 'NDMI', 'TCW'],\n",
    "    'NDMI_WNDII_FAPAR_LAI_MSAVI_NDRE_MSAVI_TCW': ['NDMI', 'WNDII', 'FAPAR', 'LAI', 'MSAVI', 'NDRE', 'TCW' ],\n",
    "    'NDMI_NDVI_TCW': ['NDMI', 'NDVI', 'TCW'],\n",
    "    'NDVI_EVI_FAPAR' : ['NDVI', 'EVI', 'FAPAR'],\n",
    "    'WNDII_NDMI' : ['WNDII', 'NDMI']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0abfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Model training and evaluation ---\n",
    "# Create DataFrame\n",
    "df = filtered_data[['ID', 'Cluster_y']].drop_duplicates()\n",
    "\n",
    "# Stratified split based on 'Cluster_y'\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, stratify=df['Cluster_y'], random_state=42)\n",
    "\n",
    "# Output\n",
    "train_output = train_df[['ID', 'Cluster_y']].sort_values('ID').reset_index(drop=True)\n",
    "test_output = test_df[['ID', 'Cluster_y']].sort_values('ID').reset_index(drop=True)\n",
    "\n",
    "train_output, test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Define C range ----\n",
    "C_values = np.logspace(1, 3, num=10)  # 1 až 1000\n",
    "\n",
    "# ---- Storage ----\n",
    "results = []\n",
    "\n",
    "# ---- Use ALL features for tuning ----\n",
    "selecting = features + ['ID', 'date', 'Cluster_y']\n",
    "selected = filtered_data[selecting]\n",
    "\n",
    "# Split data\n",
    "train = selected[selected['ID'].isin(train_output['ID'])]\n",
    "test = selected[selected['ID'].isin(test_output['ID'])]\n",
    "\n",
    "y_train = train[['Cluster_y', 'ID']].sort_values('ID').drop_duplicates(subset=['ID']).set_index(\"ID\")\n",
    "y_test = test[['Cluster_y', 'ID']].sort_values('ID').drop_duplicates(subset=['ID']).set_index(\"ID\")\n",
    "\n",
    "X_train = train.drop(['Cluster_y'], axis=1).set_index([\"ID\", \"date\"]).sort_index()\n",
    "X_test = test.drop(['Cluster_y'], axis=1).set_index([\"ID\", \"date\"]).sort_index()\n",
    "\n",
    "# ---- Loop over C ----\n",
    "for C_val in C_values:\n",
    "    print(f\"\\nTesting C = {C_val:.4f}\")\n",
    "    \n",
    "    kernel = AggrDist(RBF())\n",
    "    clf = TimeSeriesSVC(kernel=kernel, C=C_val)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.3f}, F1: {f1:.3f}\")\n",
    "    \n",
    "    results.append({'C': C_val, 'Accuracy': acc, 'F1_score': f1})\n",
    "\n",
    "# ---- Results DataFrame ----\n",
    "results_df = pd.DataFrame(results)\n",
    "best_row = results_df.loc[results_df['F1_score'].idxmax()]\n",
    "\n",
    "print(\"\\nBest C value found:\")\n",
    "print(best_row)\n",
    "\n",
    "# Plot F1 vs C\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.semilogx(results_df['C'], results_df['F1_score'], marker='o')\n",
    "plt.xlabel('C value (log scale)')\n",
    "plt.ylabel('F1 score')\n",
    "plt.title('F1 Score vs C Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f2c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Evaluate univariate and multivariate feature sets ---\n",
    "# Use the best C value for the final model\n",
    "# Classifier\n",
    "mean_gaussian_tskernel = AggrDist(RBF())\n",
    "clf = TimeSeriesSVC(kernel=mean_gaussian_tskernel, C=215.443469)\n",
    "\n",
    "accuracies = []\n",
    "f1s = []\n",
    "tested_features = features + list(multivariate_combinations.keys())  # Combine univariate + multivariate names\n",
    "\n",
    "# Loop over univariate first\n",
    "for feature in features:\n",
    "    print(f\"\\nTesting univariate: {feature}\")\n",
    "    selecting = [feature, 'ID', 'date', 'Cluster_y']\n",
    "    \n",
    "    selected = filtered_data[selecting]\n",
    "    \n",
    "    # Split\n",
    "    train = selected[selected['ID'].isin(train_output['ID'])]\n",
    "    test = selected[selected['ID'].isin(test_output['ID'])]\n",
    "    \n",
    "    # Prepare y\n",
    "    y_train = train[['Cluster_y', 'ID']].sort_values('ID').drop_duplicates(subset=['ID']).set_index(\"ID\")\n",
    "    y_test = test[['Cluster_y', 'ID']].sort_values('ID').drop_duplicates(subset=['ID']).set_index(\"ID\")\n",
    "    \n",
    "    # Prepare X\n",
    "    X_train = train.drop(['Cluster_y'], axis=1).set_index([\"ID\", \"date\"]).sort_index()\n",
    "    X_test = test.drop(['Cluster_y'], axis=1).set_index([\"ID\", \"date\"]).sort_index()\n",
    "    \n",
    "    # Fit\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"F1 score: {f1:.3f}\")\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    f1s.append(f1)\n",
    "\n",
    "# Loop over multivariate combinations\n",
    "for combo_name, combo_features in multivariate_combinations.items():\n",
    "    print(f\"\\nTesting multivariate: {combo_name}\")\n",
    "    selecting = combo_features + ['ID', 'date', 'Cluster_y']\n",
    "    \n",
    "    selected = filtered_data[selecting]\n",
    "    \n",
    "    # Split\n",
    "    train = selected[selected['ID'].isin(train_output['ID'])]\n",
    "    test = selected[selected['ID'].isin(test_output['ID'])]\n",
    "    \n",
    "    # Prepare y\n",
    "    y_train = train[['Cluster_y', 'ID']].sort_values('ID').drop_duplicates(subset=['ID']).set_index(\"ID\")\n",
    "    y_test = test[['Cluster_y', 'ID']].sort_values('ID').drop_duplicates(subset=['ID']).set_index(\"ID\")\n",
    "    \n",
    "    # Prepare X\n",
    "    X_train = train.drop(['Cluster_y'], axis=1).set_index([\"ID\", \"date\"]).sort_index()\n",
    "    X_test = test.drop(['Cluster_y'], axis=1).set_index([\"ID\", \"date\"]).sort_index()\n",
    "    \n",
    "    # Fit\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"F1 score: {f1:.3f}\")\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "final_features = features + list(multivariate_combinations.keys())\n",
    "results_df = pd.DataFrame({\n",
    "    'Feature_Set': final_features,\n",
    "    'Accuracy': accuracies,\n",
    "    'F1_score': f1s\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37220c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot F1 scores ---\n",
    "plt.figure(figsize=(14, 6))\n",
    "ax = sns.barplot(data=results_df, x='Feature_Set', y='F1_score')\n",
    "\n",
    "# Add value labels on top of the bars\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, fmt='%.2f', label_type='edge', padding=3, fontsize=10)\n",
    "\n",
    "plt.title('F1 Score', fontsize=14)\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Feature')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb5b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save the best model ---\n",
    "combination_name = \"NDVI_EVI_FAPAR\"\n",
    "if combination_name in multivariate_combinations:\n",
    "    combination_features = multivariate_combinations[combination_name]\n",
    "else:\n",
    "    raise ValueError(f\"Combination {combination_name} was not found.\")\n",
    "\n",
    "print(\"Features:\", combination_features)\n",
    "\n",
    "# Preparace dat pro model\n",
    "selecting_train = combination_features + ['ID', 'date', 'Cluster_y']\n",
    "selected_train = filtered_data[selecting_train]\n",
    "\n",
    "# Define train/test split\n",
    "train = selected_train[selected_train['ID'].isin(train_output['ID'])]\n",
    "test = selected_train[selected_train['ID'].isin(test_output['ID'])]\n",
    "\n",
    "# Prepare y and X for training\n",
    "y_train = train[['Cluster_y', 'ID']].sort_values('ID').drop_duplicates(subset=['ID']).set_index(\"ID\")\n",
    "y_test = test[['Cluster_y', 'ID']].sort_values('ID').drop_duplicates(subset=['ID']).set_index(\"ID\")\n",
    "X_train_new = train.drop(['Cluster_y'], axis=1).set_index([\"ID\", \"date\"]).sort_index()\n",
    "X_test_new = test.drop(['Cluster_y'], axis=1).set_index([\"ID\", \"date\"]).sort_index()\n",
    "\n",
    "# Train the model with the best C value\n",
    "clf_new = TimeSeriesSVC(kernel=AggrDist(RBF()), C=215.443469)\n",
    "clf_new.fit(X_train_new, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model and features\n",
    "# Save the model and features to a file\n",
    "model_data = {\n",
    "    'model': clf_new,\n",
    "    'features': combination_features,  \n",
    "    'multivariate_combinations': multivariate_combinations\n",
    "}\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model_data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
