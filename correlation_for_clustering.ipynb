{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b25010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools                    # For creating combinations of parameters\n",
    "\n",
    "import numpy as np                  # For numerical operations\n",
    "import pandas as pd                 # For data manipulation\n",
    "import matplotlib.pyplot as plt     # For plotting\n",
    "\n",
    "from IPython.display import display # For displaying DataFrames in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89952955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "# Load May export data\n",
    "data = pd.read_csv('path/to/your/data.csv', delimiter=',')\n",
    "\n",
    "# Data exploration\n",
    "print('Number of areas/polygons:', len(data['ID'].unique()))\n",
    "\n",
    "# Extract date from system:index (first 9 characters) and convert to datetime\n",
    "data = data.assign(date=data['system:index'].str[:9])\n",
    "data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48949fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter records by NDSI threshold\n",
    "filtered_data = data[data['NDSI'] < 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62901fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique IDs and dates\n",
    "unique_ids = filtered_data['ID'].unique()\n",
    "unique_dates = filtered_data['date'].unique()\n",
    "\n",
    "# Define features for correlation analysis\n",
    "features_all = ['NDVI', 'EVI', 'FAPAR', 'LAI', 'NDMI', 'MSAVI', 'NDRE', 'WNDII', 'TCW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98acf935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pearson correlation matrix for all features\n",
    "corr_all = filtered_data[features_all].corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d620c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap with correlation values\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "cax = ax.imshow(corr_all, interpolation='none', aspect='auto', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax, label='Pearson r')\n",
    "ax.set_xticks(np.arange(len(features_all)))\n",
    "ax.set_yticks(np.arange(len(features_all)))\n",
    "ax.set_xticklabels(features_all, rotation=45, ha='right')\n",
    "ax.set_yticklabels(features_all)\n",
    "ax.set_title('Pearson Correlation Matrix')\n",
    "# Annotate correlation values in each cell\n",
    "for i in range(len(features_all)):\n",
    "    for j in range(len(features_all)):\n",
    "        ax.text(j, i, f\"{corr_all.iat[i, j]:.2f}\", ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute absolute correlations and zero the diagonal\n",
    "corr_abs = corr_all.abs().copy()\n",
    "np.fill_diagonal(corr_abs.values, 0.0)\n",
    "\n",
    "# Compute average absolute correlation for each feature\n",
    "mean_abs_corr = corr_abs.mean(axis=1)\n",
    "\n",
    "# Sort features by ascending mean correlation (less redundant first)\n",
    "mean_abs_corr = mean_abs_corr.sort_values()\n",
    "print(\"Average |r| to others (lowest = least redundant):\")\n",
    "print(mean_abs_corr)\n",
    "\n",
    "# Select top n representatives (e.g., 6)\n",
    "n_reps = 6\n",
    "representatives = list(mean_abs_corr.index[:n_reps])\n",
    "print(f\"\\nSelected {n_reps} indices for clustering:\", representatives)\n",
    "\n",
    "# Generate all combinations of representatives (size â‰¥ 2)\n",
    "combos = []\n",
    "for size in range(2, len(representatives) + 1):\n",
    "    combos += list(itertools.combinations(representatives, size))\n",
    "print(\"\\nProposed combinations for time-series clustering:\")\n",
    "for c in combos:\n",
    "    print(\" \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0131a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract upper triangle of correlation matrix and sort pairs by strength\n",
    "mask = np.triu(np.ones(corr_all.shape), k=1).astype(bool)\n",
    "corr_pairs = corr_all.where(mask).stack().sort_values(ascending=True)\n",
    "\n",
    "# Print top N strongest correlated pairs\n",
    "top_n = 20\n",
    "print(f\"Top {top_n} strongest correlated pairs:\")\n",
    "print(corr_pairs.head(top_n))\n",
    "\n",
    "# Prepare combinations DataFrame\n",
    "df_combos = pd.DataFrame({\n",
    "    'Size': [len(c) for c in combos],\n",
    "    'Combination': [' & '.join(c) for c in combos]\n",
    "})\n",
    "display(df_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define forbidden pairs to exclude\n",
    "forbidden_pairs = [\n",
    "    ('WNDII', 'NDMI'),\n",
    "    ('EVI', 'MSAVI'),\n",
    "    ('WNDII', 'TCW'),\n",
    "    ('NDMI', 'TCW'),\n",
    "]\n",
    "\n",
    "# Filter out combinations containing any forbidden pair\n",
    "filtered_combos = [\n",
    "    combo for combo in combos\n",
    "    if not any(set(pair).issubset(combo) for pair in forbidden_pairs)\n",
    "]\n",
    "\n",
    "# Display filtered combinations\n",
    "df_filtered = pd.DataFrame({\n",
    "    'Size': [len(c) for c in filtered_combos],\n",
    "    'Combination': [' & '.join(c) for c in filtered_combos]\n",
    "})\n",
    "print(df_filtered)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
